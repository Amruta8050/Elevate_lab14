# Task 14: Model Comparison & Best Model Selection

## ğŸ“Œ Objective
The goal of this task is to compare multiple machine learning models on the same dataset using consistent preprocessing and evaluation metrics, and to select the best-performing model based on business-relevant criteria.

This task helps in understanding **algorithm selection**, a critical skill used by industry ML teams.

---

## ğŸ“Š Dataset
**Breast Cancer Dataset (Sklearn)**  
- Auto-generated and saved as CSV
- Binary classification problem  
- Target:
  - `0` â†’ Malignant
  - `1` â†’ Benign

---

## ğŸ›  Tools & Technologies
- Python  
- Pandas  
- Scikit-learn  
- Matplotlib  
- Joblib  

---

## ğŸ¤– Models Compared
- Logistic Regression  
- Decision Tree Classifier  
- Random Forest Classifier  
- Support Vector Machine (SVM)

---

## âš™ï¸ Approach
1. Load and save the dataset as a CSV file.
2. Perform a single train-test split (same split for all models).
3. Apply scaling where required using Pipelines.
4. Train multiple models using identical data.
5. Evaluate models using:
   - Accuracy
   - Precision
   - Recall
   - F1 Score
6. Store all evaluation metrics in a comparison table.
7. Visualize model performance using a bar chart.
8. Select the best model based on **F1 Score**.
9. Save the best-performing model for future use.

---

## ğŸ“ˆ Evaluation Metrics
- **Accuracy** â€“ Overall correctness
- **Precision** â€“ Correct positive predictions
- **Recall** â€“ Ability to capture positives
- **F1 Score** â€“ Balance between precision and recall (used for final selection)

---

#Outputs:
<img width="800" height="377" alt="Image" src="https://github.com/user-attachments/assets/91fd412c-c7dc-42f6-b328-ca581c7327c8" />
<img width="1286" height="729" alt="Image" src="https://github.com/user-attachments/assets/bcda6271-b82d-4806-ad89-e8bebd0e0c5f" />

